{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Next_word_Predictor.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VHqkKMtp-WNu"
      },
      "source": [
        "## Natural Language Processing\n",
        "\n",
        "Natural Language Processing, or NLP for short, is broadly defined as the automatic manipulation of natural language, like speech and text, by software.  NLP application\n",
        "concerned with predicting the text given in the preceding text. Auto-complete\n",
        "or suggested responses are popular types of language prediction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XolkA9Zg-yDS"
      },
      "source": [
        "## Preprocessing the Dataset\n",
        "\n",
        "The first step is to remove the unnecessary data \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tjGVDvtjL_aa"
      },
      "source": [
        "#Importing the necessary libraries\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# Other imports for processing data\n",
        "import string\n",
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cR_8R3r0ft4s"
      },
      "source": [
        "#reading the file and saving the data to list and converting the list to pandas Series\n",
        "\n",
        "file=open('/content/drive/My Drive/Colab Notebooks/Datasets/nlp.txt','r',encoding='utf8')\n",
        "lines=[]\n",
        "for i in file:\n",
        "  lines.append(i)\n",
        "\n",
        "#converting to Pandas Series\n",
        "data_file=pd.Series(lines)"
      ],
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BsMBmWfDxpE_",
        "outputId": "058398eb-daa7-4311-dc4a-35405f90ae00",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "data_file"
      ],
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0                                 No ,  he says now .\\n\n",
              "1                                And what did he do ?\\n\n",
              "2                                The money 's there .\\n\n",
              "3                     That was less than a year ago .\\n\n",
              "4                        But he made only the first .\\n\n",
              "                              ...                      \n",
              "56009    She said she 's not going out of the house .\\n\n",
              "56010                            It 's used by both .\\n\n",
              "56011                          If it has nt , do nt .\\n\n",
              "56012                               Now we have two .\\n\n",
              "56013                 There 's no way it could have bee\n",
              "Length: 56014, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 115
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vvwpQn-JMGMx"
      },
      "source": [
        "\n",
        "#Function for creating the tokenization of the input data\n",
        "def tokenizer_corpus(corpus,num_words=-1):\n",
        "  #Tokenizing\n",
        "  if num_words >-1:\n",
        "    tokenizer=Tokenizer(num_words=num_words)\n",
        "  else:\n",
        "    tokenizer=Tokenizer()\n",
        "  tokenizer.fit_on_texts(corpus)\n",
        "  \n",
        "  return tokenizer\n",
        "\n",
        "#Preprocessing of the input data and creating a corpus of the dataset\n",
        "def data_corpus(dataset):\n",
        "  #Removing Punctuatuin\n",
        "  dataset=dataset.str.replace('[{}]'.format(string.punctuation),'')\n",
        "  #converting to lowercase\n",
        "  dataset=dataset.str.lower()\n",
        "  #making one long sequence\n",
        "  dataset=dataset.str.cat()\n",
        "  corpus=dataset.split('\\n')\n",
        "  #Removing white spaces\n",
        "  for l in range(len(corpus)):\n",
        "    corpus[l]=corpus[l].rstrip()\n",
        "  #Remove empty lines\n",
        "  corpus=[l for l in corpus if l!='']\n",
        "\n",
        "  return corpus\n"
      ],
      "execution_count": 116,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xkr9TJymMJe3",
        "outputId": "2d80bd32-ec8f-4db8-8233-ae60437fa8a1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#Reading the dataset of first 1000 because even if we use the complete dataset the total unique words in the dataset is around 240.\n",
        "dataset=data_file[:1000]\n",
        "#creating the corpus\n",
        "corpus=data_corpus(dataset)\n",
        "#Tokenizing the corpus\n",
        "tokenizer=tokenizer_corpus(corpus)\n",
        "\n",
        "total_words=len(tokenizer.word_index)+1\n",
        "print('Tokenization of the input data:\\n',tokenizer.word_index)\n",
        "print('\\nTotal unique words in dataset of first 1000 :\\n',total_words)"
      ],
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tokenization of the input data:\n",
            " {'it': 1, 'to': 2, 'i': 3, 'do': 4, 'nt': 5, 'that': 6, 'he': 7, 'you': 8, 's': 9, 'the': 10, 'we': 11, 'is': 12, 'what': 13, 'said': 14, 'was': 15, 'not': 16, 'but': 17, 'know': 18, 'have': 19, 'they': 20, 'a': 21, 'this': 22, 'and': 23, 'did': 24, 'there': 25, 'be': 26, 'are': 27, 'want': 28, 'of': 29, 'time': 30, 'all': 31, 'for': 32, 'get': 33, 'in': 34, 'going': 35, 'she': 36, 'can': 37, 'go': 38, 'just': 39, 'no': 40, 'one': 41, 'would': 42, 'how': 43, 'come': 44, 'could': 45, 'like': 46, 'way': 47, 'think': 48, 'now': 49, 'will': 50, 'out': 51, 'so': 52, 'right': 53, 'people': 54, 'about': 55, 'here': 56, 'work': 57, 'them': 58, 'good': 59, 'money': 60, 'my': 61, 'does': 62, 'me': 63, 'if': 64, 'more': 65, 'had': 66, 'say': 67, 'where': 68, 'us': 69, 'life': 70, 'on': 71, 'well': 72, 'has': 73, 'much': 74, 'play': 75, 'long': 76, 'year': 77, 'been': 78, 'back': 79, 'see': 80, 'when': 81, 'never': 82, 'only': 83, 'at': 84, 'game': 85, 'as': 86, 'too': 87, 'should': 88, 'take': 89, 'last': 90, 'or': 91, 'him': 92, 'day': 93, 'who': 94, 'place': 95, 'make': 96, 'were': 97, 'with': 98, 'business': 99, 'still': 100, 'our': 101, 'some': 102, 'first': 103, 'from': 104, 'then': 105, 'any': 106, 'new': 107, 'other': 108, 'may': 109, 'team': 110, 'part': 111, 'two': 112, 'even': 113, 'best': 114, 'school': 115, 'put': 116, 'next': 117, 'man': 118, 'very': 119, 'big': 120, 'today': 121, 'home': 122, 'his': 123, 'over': 124, 'used': 125, 'her': 126, 'case': 127, 'end': 128, 'york': 129, 'made': 130, 'down': 131, 'same': 132, 'around': 133, 'city': 134, 'left': 135, 'your': 136, 'many': 137, 'most': 138, 'few': 139, 'these': 140, 'than': 141, 'up': 142, 'found': 143, 'house': 144, 'children': 145, 'show': 146, 'years': 147, 'though': 148, 'days': 149, 'family': 150, 'ago': 151, 'season': 152, 'every': 153, 'world': 154, 'use': 155, 'after': 156, 'states': 157, 'president': 158, 'might': 159, 'through': 160, 'says': 161, 'both': 162, 'into': 163, 'week': 164, 'country': 165, 'high': 166, 'because': 167, 'which': 168, 'united': 169, 'market': 170, 'their': 171, 'government': 172, 'own': 173, 'before': 174, 'another': 175, 'less': 176, 'off': 177, 'public': 178, 'second': 179, 'war': 180, 'night': 181, 'without': 182, 'also': 183, 'program': 184, 'times': 185, 'little': 186, 'three': 187, 'music': 188, 'each': 189, 'being': 190, 'those': 191, 'million': 192, 'state': 193, 'while': 194, 'an': 195, 'american': 196, 'university': 197, 'such': 198, 'national': 199, 'company': 200, 'by': 201, 'law': 202, 'office': 203, 'between': 204, 'set': 205, 'white': 206, 'court': 207, 'five': 208, 'old': 209, 'against': 210, 'women': 211, 'until': 212, 'street': 213, 'yesterday': 214, 'west': 215, 'four': 216, 'members': 217, 'several': 218, 'police': 219, 'called': 220, 'political': 221, 'john': 222, 'mr': 223, 'under': 224}\n",
            "\n",
            "Total unique words in dataset of first 1000 :\n",
            " 225\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gTRrjKG6twm7",
        "outputId": "eaaba227-90da-41a8-f49e-5b981f2a401b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "data_file.shape"
      ],
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(56014,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 119
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8SIe1JGeWExh",
        "outputId": "d52191d5-c4ba-49d6-ce16-526831bd524f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "corpus[1]"
      ],
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'and what did he do'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 120
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MWhT0VPtVo_s",
        "outputId": "5f811c8b-38cb-43a0-f92d-e6b44400ab38",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "sequences= []\n",
        "\n",
        "for line in corpus:\n",
        "  token_list=tokenizer.texts_to_sequences([line])[0]\n",
        "  #print(token_list)\n",
        "  for i in range(1,len(token_list)):\n",
        "    n_gram_sequence=token_list[:i+1]\n",
        "    #print(n_gram_sequence)\n",
        "    sequences.append(n_gram_sequence)\n",
        "#print('sequence:',sequences)\n",
        "\n",
        "#Pad Sequences for equal input length\n",
        "max_sequence_len=max([len(seq) for seq in sequences])\n",
        "sequences=np.array(pad_sequences(sequences,maxlen=max_sequence_len,padding='pre'))\n",
        "#print(sequences)\n",
        "\n",
        "#split seq between input seq and output predicted word\n",
        "input_sequences,labels=sequences[:,:-1],sequences[:,-1]\n",
        "print('Input:\\n',input_sequences)\n",
        "print('\\nnext word\\n:',labels)\n",
        "\n",
        "#one hot encoding\n",
        "one_hot_labels=tf.keras.utils.to_categorical(labels,num_classes=total_words) \n",
        "print('\\none hot labels:\\n',one_hot_labels)"
      ],
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input:\n",
            " [[  0   0   0 ...   0   0  40]\n",
            " [  0   0   0 ...   0  40   7]\n",
            " [  0   0   0 ...  40   7 161]\n",
            " ...\n",
            " [  0   0   0 ...   2  48  71]\n",
            " [  0   0   0 ...   0   0  17]\n",
            " [  0   0   0 ...   0  17  36]]\n",
            "\n",
            "next word\n",
            ": [  7 161  49 ...   1  36  14]\n",
            "\n",
            "one hot labels:\n",
            " [[0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " ...\n",
            " [0. 1. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Odu6PSPVrnX",
        "outputId": "74e23b43-82b1-4dc9-f56e-f91ff21a778a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#Tokenizer has just single index per word\n",
        "print(tokenizer.word_index['know'])\n",
        "print(tokenizer.word_index['me'])\n",
        "#input sequnces with multiple index\n",
        "print(input_sequences[5])\n",
        "print(input_sequences[6])\n",
        "#One Hot label\n",
        "print(one_hot_labels[5])\n",
        "print(one_hot_labels[6])"
      ],
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "18\n",
            "63\n",
            "[ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 23 13 24]\n",
            "[ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 23 13 24  7]\n",
            "[0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "[0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WR8AFarMWhW9"
      },
      "source": [
        "import keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense,Embedding,Bidirectional,LSTM\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n"
      ],
      "execution_count": 123,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-DsMsiVPWkc8"
      },
      "source": [
        "#creating the model\n",
        "model=Sequential()\n",
        "model.add(Embedding(total_words,64,input_length=max_sequence_len-1))\n",
        "model.add(LSTM(200,return_sequences=True))\n",
        "model.add(LSTM(200,return_sequences=True))\n",
        "model.add(LSTM(100))\n",
        "model.add(Dense(total_words,activation='softmax'))\n",
        "\n",
        "# code to find the best learning rate\n",
        "lr_schedule = keras.callbacks.LearningRateScheduler(\n",
        "    lambda epoch: 1e-3 * 10**(epoch / 30))\n",
        "\n",
        "optimizer = keras.optimizers.Adam(lr=1e-3)"
      ],
      "execution_count": 124,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vzv8bp7ra4qh"
      },
      "source": [
        ""
      ],
      "execution_count": 124,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1O8kjPBaa8XL",
        "outputId": "7200d379-8997-4a61-967b-a5ed336599d1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
        "\n",
        "model_train=model.fit(input_sequences,one_hot_labels,epochs=100,verbose=1,callbacks=[lr_schedule])"
      ],
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "177/177 [==============================] - 2s 10ms/step - loss: 4.8307 - accuracy: 0.0362\n",
            "Epoch 2/100\n",
            "177/177 [==============================] - 2s 10ms/step - loss: 4.7362 - accuracy: 0.0367\n",
            "Epoch 3/100\n",
            "177/177 [==============================] - 2s 10ms/step - loss: 4.7012 - accuracy: 0.0494\n",
            "Epoch 4/100\n",
            "177/177 [==============================] - 2s 10ms/step - loss: 4.3350 - accuracy: 0.1031\n",
            "Epoch 5/100\n",
            "177/177 [==============================] - 2s 10ms/step - loss: 3.9811 - accuracy: 0.1496\n",
            "Epoch 6/100\n",
            "177/177 [==============================] - 2s 11ms/step - loss: 3.8060 - accuracy: 0.1722\n",
            "Epoch 7/100\n",
            "177/177 [==============================] - 2s 10ms/step - loss: 3.6875 - accuracy: 0.1780\n",
            "Epoch 8/100\n",
            "177/177 [==============================] - 2s 10ms/step - loss: 3.5876 - accuracy: 0.1826\n",
            "Epoch 9/100\n",
            "177/177 [==============================] - 2s 10ms/step - loss: 3.4998 - accuracy: 0.1969\n",
            "Epoch 10/100\n",
            "177/177 [==============================] - 2s 10ms/step - loss: 3.4423 - accuracy: 0.1953\n",
            "Epoch 11/100\n",
            "177/177 [==============================] - 2s 10ms/step - loss: 3.3841 - accuracy: 0.2070\n",
            "Epoch 12/100\n",
            "177/177 [==============================] - 2s 11ms/step - loss: 3.3306 - accuracy: 0.2082\n",
            "Epoch 13/100\n",
            "177/177 [==============================] - 2s 10ms/step - loss: 3.2846 - accuracy: 0.2137\n",
            "Epoch 14/100\n",
            "177/177 [==============================] - 2s 10ms/step - loss: 3.2332 - accuracy: 0.2193\n",
            "Epoch 15/100\n",
            "177/177 [==============================] - 2s 10ms/step - loss: 3.1845 - accuracy: 0.2214\n",
            "Epoch 16/100\n",
            "177/177 [==============================] - 2s 10ms/step - loss: 3.1424 - accuracy: 0.2306\n",
            "Epoch 17/100\n",
            "177/177 [==============================] - 2s 10ms/step - loss: 3.0910 - accuracy: 0.2336\n",
            "Epoch 18/100\n",
            "177/177 [==============================] - 2s 10ms/step - loss: 3.0607 - accuracy: 0.2380\n",
            "Epoch 19/100\n",
            "177/177 [==============================] - 2s 10ms/step - loss: 3.0000 - accuracy: 0.2483\n",
            "Epoch 20/100\n",
            "177/177 [==============================] - 2s 10ms/step - loss: 2.9489 - accuracy: 0.2543\n",
            "Epoch 21/100\n",
            "177/177 [==============================] - 2s 10ms/step - loss: 2.9160 - accuracy: 0.2571\n",
            "Epoch 22/100\n",
            "177/177 [==============================] - 2s 10ms/step - loss: 2.9679 - accuracy: 0.2525\n",
            "Epoch 23/100\n",
            "177/177 [==============================] - 2s 10ms/step - loss: 2.8841 - accuracy: 0.2592\n",
            "Epoch 24/100\n",
            "177/177 [==============================] - 2s 10ms/step - loss: 2.8315 - accuracy: 0.2666\n",
            "Epoch 25/100\n",
            "177/177 [==============================] - 2s 10ms/step - loss: 2.7898 - accuracy: 0.2712\n",
            "Epoch 26/100\n",
            "177/177 [==============================] - 2s 10ms/step - loss: 2.7544 - accuracy: 0.2702\n",
            "Epoch 27/100\n",
            "177/177 [==============================] - 2s 10ms/step - loss: 2.7380 - accuracy: 0.2737\n",
            "Epoch 28/100\n",
            "177/177 [==============================] - 2s 10ms/step - loss: 2.7136 - accuracy: 0.2749\n",
            "Epoch 29/100\n",
            "177/177 [==============================] - 2s 10ms/step - loss: 2.7003 - accuracy: 0.2868\n",
            "Epoch 30/100\n",
            "177/177 [==============================] - 2s 10ms/step - loss: 2.7339 - accuracy: 0.2705\n",
            "Epoch 31/100\n",
            "177/177 [==============================] - 2s 10ms/step - loss: 2.7483 - accuracy: 0.2723\n",
            "Epoch 32/100\n",
            "177/177 [==============================] - 2s 10ms/step - loss: 2.7800 - accuracy: 0.2732\n",
            "Epoch 33/100\n",
            "177/177 [==============================] - 2s 10ms/step - loss: 2.8305 - accuracy: 0.2576\n",
            "Epoch 34/100\n",
            "177/177 [==============================] - 2s 10ms/step - loss: 2.8295 - accuracy: 0.2596\n",
            "Epoch 35/100\n",
            "177/177 [==============================] - 2s 11ms/step - loss: 2.8633 - accuracy: 0.2557\n",
            "Epoch 36/100\n",
            "177/177 [==============================] - 2s 10ms/step - loss: 2.9362 - accuracy: 0.2349\n",
            "Epoch 37/100\n",
            "177/177 [==============================] - 2s 10ms/step - loss: 2.9996 - accuracy: 0.2317\n",
            "Epoch 38/100\n",
            "177/177 [==============================] - 2s 10ms/step - loss: 3.1435 - accuracy: 0.2147\n",
            "Epoch 39/100\n",
            "177/177 [==============================] - 2s 10ms/step - loss: 3.2954 - accuracy: 0.2078\n",
            "Epoch 40/100\n",
            "177/177 [==============================] - 2s 10ms/step - loss: 3.3923 - accuracy: 0.1849\n",
            "Epoch 41/100\n",
            "177/177 [==============================] - 2s 11ms/step - loss: 3.2986 - accuracy: 0.1976\n",
            "Epoch 42/100\n",
            "177/177 [==============================] - 2s 10ms/step - loss: 3.2943 - accuracy: 0.1988\n",
            "Epoch 43/100\n",
            "177/177 [==============================] - 2s 11ms/step - loss: 3.4206 - accuracy: 0.1882\n",
            "Epoch 44/100\n",
            "177/177 [==============================] - 2s 10ms/step - loss: 3.3938 - accuracy: 0.1893\n",
            "Epoch 45/100\n",
            "177/177 [==============================] - 2s 10ms/step - loss: 3.4739 - accuracy: 0.1782\n",
            "Epoch 46/100\n",
            "177/177 [==============================] - 2s 11ms/step - loss: 3.7026 - accuracy: 0.1618\n",
            "Epoch 47/100\n",
            "177/177 [==============================] - 2s 10ms/step - loss: 3.9666 - accuracy: 0.1395\n",
            "Epoch 48/100\n",
            "177/177 [==============================] - 2s 10ms/step - loss: 3.9689 - accuracy: 0.1391\n",
            "Epoch 49/100\n",
            "177/177 [==============================] - 2s 10ms/step - loss: 3.9129 - accuracy: 0.1411\n",
            "Epoch 50/100\n",
            "177/177 [==============================] - 2s 10ms/step - loss: 3.9580 - accuracy: 0.1347\n",
            "Epoch 51/100\n",
            "177/177 [==============================] - 2s 10ms/step - loss: 3.9549 - accuracy: 0.1393\n",
            "Epoch 52/100\n",
            "177/177 [==============================] - 2s 10ms/step - loss: 4.0472 - accuracy: 0.1340\n",
            "Epoch 53/100\n",
            "177/177 [==============================] - 2s 10ms/step - loss: 4.0274 - accuracy: 0.1312\n",
            "Epoch 54/100\n",
            "177/177 [==============================] - 2s 10ms/step - loss: 4.1545 - accuracy: 0.1220\n",
            "Epoch 55/100\n",
            "177/177 [==============================] - 2s 10ms/step - loss: 4.3134 - accuracy: 0.0966\n",
            "Epoch 56/100\n",
            "177/177 [==============================] - 2s 10ms/step - loss: 4.4024 - accuracy: 0.0920\n",
            "Epoch 57/100\n",
            "177/177 [==============================] - 2s 10ms/step - loss: 4.4538 - accuracy: 0.0851\n",
            "Epoch 58/100\n",
            "177/177 [==============================] - 2s 11ms/step - loss: 4.5647 - accuracy: 0.0689\n",
            "Epoch 59/100\n",
            "177/177 [==============================] - 2s 10ms/step - loss: 4.5333 - accuracy: 0.0625\n",
            "Epoch 60/100\n",
            "177/177 [==============================] - 2s 11ms/step - loss: 4.6834 - accuracy: 0.0487\n",
            "Epoch 61/100\n",
            "177/177 [==============================] - 2s 10ms/step - loss: 4.6829 - accuracy: 0.0486\n",
            "Epoch 62/100\n",
            "177/177 [==============================] - 2s 10ms/step - loss: 4.6741 - accuracy: 0.0526\n",
            "Epoch 63/100\n",
            "177/177 [==============================] - 2s 10ms/step - loss: 4.6513 - accuracy: 0.0572\n",
            "Epoch 64/100\n",
            "177/177 [==============================] - 2s 10ms/step - loss: 4.6401 - accuracy: 0.0532\n",
            "Epoch 65/100\n",
            "177/177 [==============================] - 2s 10ms/step - loss: 4.7161 - accuracy: 0.0535\n",
            "Epoch 66/100\n",
            "177/177 [==============================] - 2s 11ms/step - loss: 4.7864 - accuracy: 0.0381\n",
            "Epoch 67/100\n",
            "177/177 [==============================] - 2s 11ms/step - loss: 4.7951 - accuracy: 0.0350\n",
            "Epoch 68/100\n",
            "177/177 [==============================] - 2s 11ms/step - loss: 4.8024 - accuracy: 0.0334\n",
            "Epoch 69/100\n",
            "177/177 [==============================] - 2s 10ms/step - loss: 4.8084 - accuracy: 0.0380\n",
            "Epoch 70/100\n",
            "177/177 [==============================] - 2s 10ms/step - loss: 4.8182 - accuracy: 0.0357\n",
            "Epoch 71/100\n",
            "177/177 [==============================] - 2s 10ms/step - loss: 4.8244 - accuracy: 0.0373\n",
            "Epoch 72/100\n",
            "177/177 [==============================] - 2s 10ms/step - loss: 4.8367 - accuracy: 0.0380\n",
            "Epoch 73/100\n",
            "177/177 [==============================] - 2s 10ms/step - loss: 4.8419 - accuracy: 0.0346\n",
            "Epoch 74/100\n",
            "177/177 [==============================] - 2s 10ms/step - loss: 4.8579 - accuracy: 0.0362\n",
            "Epoch 75/100\n",
            "177/177 [==============================] - 2s 10ms/step - loss: 4.8576 - accuracy: 0.0311\n",
            "Epoch 76/100\n",
            "177/177 [==============================] - 2s 11ms/step - loss: 4.8799 - accuracy: 0.0358\n",
            "Epoch 77/100\n",
            "177/177 [==============================] - 2s 10ms/step - loss: 4.9019 - accuracy: 0.0332\n",
            "Epoch 78/100\n",
            "177/177 [==============================] - 2s 10ms/step - loss: 4.9096 - accuracy: 0.0321\n",
            "Epoch 79/100\n",
            "177/177 [==============================] - 2s 10ms/step - loss: 4.9237 - accuracy: 0.0305\n",
            "Epoch 80/100\n",
            "177/177 [==============================] - 2s 11ms/step - loss: 4.9412 - accuracy: 0.0284\n",
            "Epoch 81/100\n",
            "177/177 [==============================] - 2s 11ms/step - loss: 4.9504 - accuracy: 0.0337\n",
            "Epoch 82/100\n",
            "177/177 [==============================] - 2s 10ms/step - loss: 4.9717 - accuracy: 0.0406\n",
            "Epoch 83/100\n",
            "177/177 [==============================] - 2s 11ms/step - loss: 5.0017 - accuracy: 0.0279\n",
            "Epoch 84/100\n",
            "177/177 [==============================] - 2s 11ms/step - loss: 5.8907 - accuracy: 0.0261\n",
            "Epoch 85/100\n",
            "177/177 [==============================] - 2s 10ms/step - loss: 6.0286 - accuracy: 0.0230\n",
            "Epoch 86/100\n",
            "177/177 [==============================] - 2s 10ms/step - loss: 5.8018 - accuracy: 0.0256\n",
            "Epoch 87/100\n",
            "177/177 [==============================] - 2s 11ms/step - loss: 5.7981 - accuracy: 0.0298\n",
            "Epoch 88/100\n",
            "177/177 [==============================] - 2s 10ms/step - loss: 5.8132 - accuracy: 0.0251\n",
            "Epoch 89/100\n",
            "177/177 [==============================] - 2s 10ms/step - loss: 5.8053 - accuracy: 0.0228\n",
            "Epoch 90/100\n",
            "177/177 [==============================] - 2s 10ms/step - loss: 5.8532 - accuracy: 0.0267\n",
            "Epoch 91/100\n",
            "177/177 [==============================] - 2s 10ms/step - loss: 5.9408 - accuracy: 0.0240\n",
            "Epoch 92/100\n",
            "177/177 [==============================] - 2s 10ms/step - loss: 29.8408 - accuracy: 0.0219\n",
            "Epoch 93/100\n",
            "177/177 [==============================] - 2s 10ms/step - loss: 56.9446 - accuracy: 0.0134\n",
            "Epoch 94/100\n",
            "177/177 [==============================] - 2s 10ms/step - loss: 46.5628 - accuracy: 0.0125\n",
            "Epoch 95/100\n",
            "177/177 [==============================] - 2s 10ms/step - loss: 36.9030 - accuracy: 0.0136\n",
            "Epoch 96/100\n",
            "177/177 [==============================] - 2s 10ms/step - loss: 23.7316 - accuracy: 0.0136\n",
            "Epoch 97/100\n",
            "177/177 [==============================] - 2s 10ms/step - loss: 22.3314 - accuracy: 0.0136\n",
            "Epoch 98/100\n",
            "177/177 [==============================] - 2s 10ms/step - loss: 69.7554 - accuracy: 0.0143\n",
            "Epoch 99/100\n",
            "177/177 [==============================] - 2s 10ms/step - loss: 52.9331 - accuracy: 0.0152\n",
            "Epoch 100/100\n",
            "177/177 [==============================] - 2s 10ms/step - loss: 44.7349 - accuracy: 0.0131\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VBFEV5wE9iJd",
        "outputId": "ded92285-61fd-45f4-9a80-ca74305242da",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.semilogx(model_train.history[\"lr\"], model_train.history[\"loss\"])\n",
        "plt.axis([1e-3, 10, 0, 15])"
      ],
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.001, 10.0, 0.0, 15.0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 126
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DDB0NX4qYHTd"
      },
      "source": [
        "Here we can see that the loss is increasing after 1e-2 hence we can choose the learning rate as 1e-2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DA6Fl06q-o0G"
      },
      "source": [
        "\n",
        "\n",
        "model=Sequential()\n",
        "model.add(Embedding(total_words,64,input_length=max_sequence_len-1))\n",
        "model.add(LSTM(200,return_sequences=True))\n",
        "model.add(LSTM(200,return_sequences=True))\n",
        "model.add(LSTM(100))\n",
        "model.add(Dense(total_words,activation='relu'))\n",
        "model.add(Dense(total_words,activation='softmax'))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "optimizer = keras.optimizers.Adam(lr=1e-2)\n"
      ],
      "execution_count": 127,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xApXGneuDhGs",
        "outputId": "faacb0c8-14ab-49d2-a54a-553584c5f6b0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_10\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_10 (Embedding)     (None, 22, 64)            14400     \n",
            "_________________________________________________________________\n",
            "lstm_30 (LSTM)               (None, 22, 200)           212000    \n",
            "_________________________________________________________________\n",
            "lstm_31 (LSTM)               (None, 22, 200)           320800    \n",
            "_________________________________________________________________\n",
            "lstm_32 (LSTM)               (None, 100)               120400    \n",
            "_________________________________________________________________\n",
            "dense_15 (Dense)             (None, 225)               22725     \n",
            "_________________________________________________________________\n",
            "dense_16 (Dense)             (None, 225)               50850     \n",
            "=================================================================\n",
            "Total params: 741,175\n",
            "Trainable params: 741,175\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ct5UYgZjDjfe",
        "outputId": "f98e42f0-c7cb-4c92-a9f3-469f33437008",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
        "\n",
        "model_train=model.fit(input_sequences,one_hot_labels,epochs=200,verbose=1)"
      ],
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "177/177 [==============================] - 2s 10ms/step - loss: 4.8226 - accuracy: 0.0336\n",
            "Epoch 2/200\n",
            "177/177 [==============================] - 2s 10ms/step - loss: 4.7379 - accuracy: 0.0378\n",
            "Epoch 3/200\n",
            "177/177 [==============================] - 2s 10ms/step - loss: 4.6593 - accuracy: 0.0410\n",
            "Epoch 4/200\n",
            "177/177 [==============================] - 2s 10ms/step - loss: 4.4286 - accuracy: 0.0726\n",
            "Epoch 5/200\n",
            "177/177 [==============================] - 2s 10ms/step - loss: 4.1345 - accuracy: 0.1026\n",
            "Epoch 6/200\n",
            "177/177 [==============================] - 2s 10ms/step - loss: 3.9572 - accuracy: 0.1289\n",
            "Epoch 7/200\n",
            "177/177 [==============================] - 2s 10ms/step - loss: 3.8369 - accuracy: 0.1483\n",
            "Epoch 8/200\n",
            "177/177 [==============================] - 2s 10ms/step - loss: 3.7340 - accuracy: 0.1584\n",
            "Epoch 9/200\n",
            "177/177 [==============================] - 2s 11ms/step - loss: 3.6345 - accuracy: 0.1670\n",
            "Epoch 10/200\n",
            "177/177 [==============================] - 2s 11ms/step - loss: 3.5513 - accuracy: 0.1702\n",
            "Epoch 11/200\n",
            "177/177 [==============================] - 2s 10ms/step - loss: 3.4783 - accuracy: 0.1794\n",
            "Epoch 12/200\n",
            "177/177 [==============================] - 2s 10ms/step - loss: 3.4160 - accuracy: 0.1919\n",
            "Epoch 13/200\n",
            "177/177 [==============================] - 2s 10ms/step - loss: 3.3479 - accuracy: 0.1992\n",
            "Epoch 14/200\n",
            "177/177 [==============================] - 2s 10ms/step - loss: 3.2965 - accuracy: 0.2084\n",
            "Epoch 15/200\n",
            "177/177 [==============================] - 2s 10ms/step - loss: 3.2429 - accuracy: 0.2115\n",
            "Epoch 16/200\n",
            "177/177 [==============================] - 2s 10ms/step - loss: 3.1956 - accuracy: 0.2183\n",
            "Epoch 17/200\n",
            "177/177 [==============================] - 2s 10ms/step - loss: 3.1417 - accuracy: 0.2244\n",
            "Epoch 18/200\n",
            "177/177 [==============================] - 2s 10ms/step - loss: 3.1012 - accuracy: 0.2299\n",
            "Epoch 19/200\n",
            "177/177 [==============================] - 2s 10ms/step - loss: 3.0468 - accuracy: 0.2333\n",
            "Epoch 20/200\n",
            "177/177 [==============================] - 2s 10ms/step - loss: 3.0038 - accuracy: 0.2313\n",
            "Epoch 21/200\n",
            "177/177 [==============================] - 2s 10ms/step - loss: 2.9609 - accuracy: 0.2386\n",
            "Epoch 22/200\n",
            "177/177 [==============================] - 2s 10ms/step - loss: 2.9174 - accuracy: 0.2476\n",
            "Epoch 23/200\n",
            "177/177 [==============================] - 2s 10ms/step - loss: 2.8654 - accuracy: 0.2530\n",
            "Epoch 24/200\n",
            "177/177 [==============================] - 2s 10ms/step - loss: 2.8227 - accuracy: 0.2550\n",
            "Epoch 25/200\n",
            "177/177 [==============================] - 2s 10ms/step - loss: 2.7839 - accuracy: 0.2645\n",
            "Epoch 26/200\n",
            "177/177 [==============================] - 2s 10ms/step - loss: 2.7403 - accuracy: 0.2684\n",
            "Epoch 27/200\n",
            "177/177 [==============================] - 2s 10ms/step - loss: 2.6834 - accuracy: 0.2771\n",
            "Epoch 28/200\n",
            "177/177 [==============================] - 2s 11ms/step - loss: 2.6484 - accuracy: 0.2859\n",
            "Epoch 29/200\n",
            "177/177 [==============================] - 2s 11ms/step - loss: 2.6102 - accuracy: 0.2885\n",
            "Epoch 30/200\n",
            "177/177 [==============================] - 2s 10ms/step - loss: 2.5553 - accuracy: 0.3014\n",
            "Epoch 31/200\n",
            "177/177 [==============================] - 2s 10ms/step - loss: 2.5104 - accuracy: 0.3150\n",
            "Epoch 32/200\n",
            "177/177 [==============================] - 2s 10ms/step - loss: 2.4744 - accuracy: 0.3131\n",
            "Epoch 33/200\n",
            "177/177 [==============================] - 2s 10ms/step - loss: 2.4197 - accuracy: 0.3288\n",
            "Epoch 34/200\n",
            "177/177 [==============================] - 2s 10ms/step - loss: 2.3838 - accuracy: 0.3390\n",
            "Epoch 35/200\n",
            "177/177 [==============================] - 2s 10ms/step - loss: 2.3343 - accuracy: 0.3463\n",
            "Epoch 36/200\n",
            "177/177 [==============================] - 2s 10ms/step - loss: 2.2929 - accuracy: 0.3558\n",
            "Epoch 37/200\n",
            "177/177 [==============================] - 2s 10ms/step - loss: 2.2429 - accuracy: 0.3708\n",
            "Epoch 38/200\n",
            "177/177 [==============================] - 2s 10ms/step - loss: 2.2028 - accuracy: 0.3786\n",
            "Epoch 39/200\n",
            "177/177 [==============================] - 2s 10ms/step - loss: 2.1555 - accuracy: 0.3853\n",
            "Epoch 40/200\n",
            "177/177 [==============================] - 2s 10ms/step - loss: 2.1091 - accuracy: 0.4005\n",
            "Epoch 41/200\n",
            "177/177 [==============================] - 2s 10ms/step - loss: 2.0689 - accuracy: 0.4081\n",
            "Epoch 42/200\n",
            "177/177 [==============================] - 2s 10ms/step - loss: 2.0375 - accuracy: 0.4127\n",
            "Epoch 43/200\n",
            "177/177 [==============================] - 2s 12ms/step - loss: 2.0003 - accuracy: 0.4249\n",
            "Epoch 44/200\n",
            "177/177 [==============================] - 2s 11ms/step - loss: 1.9603 - accuracy: 0.4400\n",
            "Epoch 45/200\n",
            "177/177 [==============================] - 2s 11ms/step - loss: 1.9205 - accuracy: 0.4464\n",
            "Epoch 46/200\n",
            "177/177 [==============================] - 2s 11ms/step - loss: 1.8722 - accuracy: 0.4634\n",
            "Epoch 47/200\n",
            "177/177 [==============================] - 2s 12ms/step - loss: 1.8330 - accuracy: 0.4708\n",
            "Epoch 48/200\n",
            "177/177 [==============================] - 2s 12ms/step - loss: 1.8098 - accuracy: 0.4745\n",
            "Epoch 49/200\n",
            "177/177 [==============================] - 2s 10ms/step - loss: 1.7656 - accuracy: 0.4895\n",
            "Epoch 50/200\n",
            "177/177 [==============================] - 2s 10ms/step - loss: 1.7338 - accuracy: 0.4978\n",
            "Epoch 51/200\n",
            "177/177 [==============================] - 2s 10ms/step - loss: 1.6956 - accuracy: 0.5098\n",
            "Epoch 52/200\n",
            "177/177 [==============================] - 2s 10ms/step - loss: 1.6652 - accuracy: 0.5142\n",
            "Epoch 53/200\n",
            "177/177 [==============================] - 2s 11ms/step - loss: 1.6317 - accuracy: 0.5273\n",
            "Epoch 54/200\n",
            "177/177 [==============================] - 2s 11ms/step - loss: 1.6009 - accuracy: 0.5414\n",
            "Epoch 55/200\n",
            "177/177 [==============================] - 2s 11ms/step - loss: 1.5762 - accuracy: 0.5398\n",
            "Epoch 56/200\n",
            "177/177 [==============================] - 2s 11ms/step - loss: 1.5380 - accuracy: 0.5559\n",
            "Epoch 57/200\n",
            "177/177 [==============================] - 2s 11ms/step - loss: 1.5138 - accuracy: 0.5538\n",
            "Epoch 58/200\n",
            "177/177 [==============================] - 2s 10ms/step - loss: 1.4806 - accuracy: 0.5700\n",
            "Epoch 59/200\n",
            "177/177 [==============================] - 2s 11ms/step - loss: 1.4601 - accuracy: 0.5746\n",
            "Epoch 60/200\n",
            "177/177 [==============================] - 2s 10ms/step - loss: 1.4278 - accuracy: 0.5891\n",
            "Epoch 61/200\n",
            "177/177 [==============================] - 2s 10ms/step - loss: 1.4004 - accuracy: 0.5947\n",
            "Epoch 62/200\n",
            "177/177 [==============================] - 2s 10ms/step - loss: 1.3790 - accuracy: 0.5960\n",
            "Epoch 63/200\n",
            "177/177 [==============================] - 2s 10ms/step - loss: 1.3509 - accuracy: 0.6062\n",
            "Epoch 64/200\n",
            "177/177 [==============================] - 2s 10ms/step - loss: 1.3308 - accuracy: 0.6127\n",
            "Epoch 65/200\n",
            "177/177 [==============================] - 2s 10ms/step - loss: 1.3152 - accuracy: 0.6138\n",
            "Epoch 66/200\n",
            "177/177 [==============================] - 2s 10ms/step - loss: 1.2922 - accuracy: 0.6235\n",
            "Epoch 67/200\n",
            "177/177 [==============================] - 2s 10ms/step - loss: 1.2749 - accuracy: 0.6212\n",
            "Epoch 68/200\n",
            "177/177 [==============================] - 2s 10ms/step - loss: 1.2528 - accuracy: 0.6345\n",
            "Epoch 69/200\n",
            "177/177 [==============================] - 2s 10ms/step - loss: 1.2400 - accuracy: 0.6318\n",
            "Epoch 70/200\n",
            "177/177 [==============================] - 2s 10ms/step - loss: 1.2196 - accuracy: 0.6387\n",
            "Epoch 71/200\n",
            "177/177 [==============================] - 2s 11ms/step - loss: 1.1954 - accuracy: 0.6509\n",
            "Epoch 72/200\n",
            "177/177 [==============================] - 2s 10ms/step - loss: 1.1728 - accuracy: 0.6530\n",
            "Epoch 73/200\n",
            "177/177 [==============================] - 2s 11ms/step - loss: 1.1638 - accuracy: 0.6527\n",
            "Epoch 74/200\n",
            "177/177 [==============================] - 2s 11ms/step - loss: 1.1502 - accuracy: 0.6601\n",
            "Epoch 75/200\n",
            "177/177 [==============================] - 2s 10ms/step - loss: 1.1361 - accuracy: 0.6603\n",
            "Epoch 76/200\n",
            "177/177 [==============================] - 2s 11ms/step - loss: 1.1371 - accuracy: 0.6597\n",
            "Epoch 77/200\n",
            "177/177 [==============================] - 2s 11ms/step - loss: 1.1094 - accuracy: 0.6698\n",
            "Epoch 78/200\n",
            "177/177 [==============================] - 2s 10ms/step - loss: 1.0894 - accuracy: 0.6701\n",
            "Epoch 79/200\n",
            "177/177 [==============================] - 2s 10ms/step - loss: 1.0763 - accuracy: 0.6740\n",
            "Epoch 80/200\n",
            "177/177 [==============================] - 2s 11ms/step - loss: 1.0660 - accuracy: 0.6763\n",
            "Epoch 81/200\n",
            "177/177 [==============================] - 2s 11ms/step - loss: 1.0510 - accuracy: 0.6825\n",
            "Epoch 82/200\n",
            "177/177 [==============================] - 2s 10ms/step - loss: 1.0435 - accuracy: 0.6837\n",
            "Epoch 83/200\n",
            "177/177 [==============================] - 2s 10ms/step - loss: 1.0225 - accuracy: 0.6882\n",
            "Epoch 84/200\n",
            "177/177 [==============================] - 2s 10ms/step - loss: 1.0226 - accuracy: 0.6871\n",
            "Epoch 85/200\n",
            "177/177 [==============================] - 2s 10ms/step - loss: 1.0087 - accuracy: 0.6931\n",
            "Epoch 86/200\n",
            "177/177 [==============================] - 2s 10ms/step - loss: 0.9976 - accuracy: 0.6982\n",
            "Epoch 87/200\n",
            "177/177 [==============================] - 2s 11ms/step - loss: 0.9965 - accuracy: 0.6933\n",
            "Epoch 88/200\n",
            "177/177 [==============================] - 2s 10ms/step - loss: 0.9927 - accuracy: 0.6998\n",
            "Epoch 89/200\n",
            "177/177 [==============================] - 2s 10ms/step - loss: 0.9760 - accuracy: 0.6950\n",
            "Epoch 90/200\n",
            "177/177 [==============================] - 2s 11ms/step - loss: 0.9644 - accuracy: 0.6995\n",
            "Epoch 91/200\n",
            "177/177 [==============================] - 2s 11ms/step - loss: 0.9616 - accuracy: 0.6979\n",
            "Epoch 92/200\n",
            "177/177 [==============================] - 2s 10ms/step - loss: 0.9453 - accuracy: 0.7048\n",
            "Epoch 93/200\n",
            "177/177 [==============================] - 2s 10ms/step - loss: 0.9411 - accuracy: 0.7063\n",
            "Epoch 94/200\n",
            "177/177 [==============================] - 2s 11ms/step - loss: 0.9474 - accuracy: 0.7017\n",
            "Epoch 95/200\n",
            "177/177 [==============================] - 2s 10ms/step - loss: 0.9505 - accuracy: 0.7026\n",
            "Epoch 96/200\n",
            "177/177 [==============================] - 2s 10ms/step - loss: 0.9309 - accuracy: 0.7078\n",
            "Epoch 97/200\n",
            "177/177 [==============================] - 2s 11ms/step - loss: 0.9167 - accuracy: 0.7125\n",
            "Epoch 98/200\n",
            "177/177 [==============================] - 2s 10ms/step - loss: 0.9054 - accuracy: 0.7122\n",
            "Epoch 99/200\n",
            "177/177 [==============================] - 2s 10ms/step - loss: 0.9002 - accuracy: 0.7175\n",
            "Epoch 100/200\n",
            "177/177 [==============================] - 2s 10ms/step - loss: 0.8919 - accuracy: 0.7150\n",
            "Epoch 101/200\n",
            "177/177 [==============================] - 2s 10ms/step - loss: 0.8973 - accuracy: 0.7159\n",
            "Epoch 102/200\n",
            "177/177 [==============================] - 2s 10ms/step - loss: 0.8906 - accuracy: 0.7134\n",
            "Epoch 103/200\n",
            "177/177 [==============================] - 2s 10ms/step - loss: 0.8835 - accuracy: 0.7173\n",
            "Epoch 104/200\n",
            "177/177 [==============================] - 2s 10ms/step - loss: 0.8795 - accuracy: 0.7150\n",
            "Epoch 105/200\n",
            "177/177 [==============================] - 2s 11ms/step - loss: 0.8832 - accuracy: 0.7187\n",
            "Epoch 106/200\n",
            "177/177 [==============================] - 2s 10ms/step - loss: 0.8830 - accuracy: 0.7178\n",
            "Epoch 107/200\n",
            "177/177 [==============================] - 2s 10ms/step - loss: 0.8734 - accuracy: 0.7215\n",
            "Epoch 108/200\n",
            "177/177 [==============================] - 2s 10ms/step - loss: 0.8703 - accuracy: 0.7205\n",
            "Epoch 109/200\n",
            "177/177 [==============================] - 2s 10ms/step - loss: 0.8485 - accuracy: 0.7205\n",
            "Epoch 110/200\n",
            "177/177 [==============================] - 2s 11ms/step - loss: 0.8479 - accuracy: 0.7252\n",
            "Epoch 111/200\n",
            "177/177 [==============================] - 2s 10ms/step - loss: 0.8448 - accuracy: 0.7277\n",
            "Epoch 112/200\n",
            "177/177 [==============================] - 2s 11ms/step - loss: 0.8404 - accuracy: 0.7263\n",
            "Epoch 113/200\n",
            "177/177 [==============================] - 2s 10ms/step - loss: 0.8384 - accuracy: 0.7244\n",
            "Epoch 114/200\n",
            "177/177 [==============================] - 2s 11ms/step - loss: 0.8316 - accuracy: 0.7263\n",
            "Epoch 115/200\n",
            "177/177 [==============================] - 2s 10ms/step - loss: 0.8476 - accuracy: 0.7244\n",
            "Epoch 116/200\n",
            "177/177 [==============================] - 2s 10ms/step - loss: 0.8473 - accuracy: 0.7198\n",
            "Epoch 117/200\n",
            "177/177 [==============================] - 2s 10ms/step - loss: 0.8438 - accuracy: 0.7251\n",
            "Epoch 118/200\n",
            "177/177 [==============================] - 2s 10ms/step - loss: 0.8313 - accuracy: 0.7251\n",
            "Epoch 119/200\n",
            "177/177 [==============================] - 2s 10ms/step - loss: 0.8189 - accuracy: 0.7265\n",
            "Epoch 120/200\n",
            "177/177 [==============================] - 2s 11ms/step - loss: 0.8104 - accuracy: 0.7291\n",
            "Epoch 121/200\n",
            "177/177 [==============================] - 2s 10ms/step - loss: 0.8136 - accuracy: 0.7288\n",
            "Epoch 122/200\n",
            "177/177 [==============================] - 2s 10ms/step - loss: 0.8123 - accuracy: 0.7281\n",
            "Epoch 123/200\n",
            "177/177 [==============================] - 2s 10ms/step - loss: 0.8130 - accuracy: 0.7279\n",
            "Epoch 124/200\n",
            "177/177 [==============================] - 2s 10ms/step - loss: 0.8383 - accuracy: 0.7189\n",
            "Epoch 125/200\n",
            "177/177 [==============================] - 2s 10ms/step - loss: 0.8254 - accuracy: 0.7244\n",
            "Epoch 126/200\n",
            "177/177 [==============================] - 2s 10ms/step - loss: 0.8161 - accuracy: 0.7268\n",
            "Epoch 127/200\n",
            "177/177 [==============================] - 2s 10ms/step - loss: 0.8351 - accuracy: 0.7259\n",
            "Epoch 128/200\n",
            "177/177 [==============================] - 2s 10ms/step - loss: 0.8375 - accuracy: 0.7240\n",
            "Epoch 129/200\n",
            "177/177 [==============================] - 2s 10ms/step - loss: 0.8184 - accuracy: 0.7281\n",
            "Epoch 130/200\n",
            "177/177 [==============================] - 2s 10ms/step - loss: 0.7917 - accuracy: 0.7295\n",
            "Epoch 131/200\n",
            "177/177 [==============================] - 2s 11ms/step - loss: 0.7883 - accuracy: 0.7323\n",
            "Epoch 132/200\n",
            "177/177 [==============================] - 2s 10ms/step - loss: 0.7863 - accuracy: 0.7348\n",
            "Epoch 133/200\n",
            "177/177 [==============================] - 2s 10ms/step - loss: 0.7786 - accuracy: 0.7346\n",
            "Epoch 134/200\n",
            "177/177 [==============================] - 2s 10ms/step - loss: 0.7786 - accuracy: 0.7327\n",
            "Epoch 135/200\n",
            "177/177 [==============================] - 2s 10ms/step - loss: 0.7862 - accuracy: 0.7328\n",
            "Epoch 136/200\n",
            "177/177 [==============================] - 2s 10ms/step - loss: 0.7868 - accuracy: 0.7323\n",
            "Epoch 137/200\n",
            "177/177 [==============================] - 2s 11ms/step - loss: 0.7930 - accuracy: 0.7334\n",
            "Epoch 138/200\n",
            "177/177 [==============================] - 2s 10ms/step - loss: 0.8024 - accuracy: 0.7249\n",
            "Epoch 139/200\n",
            "177/177 [==============================] - 2s 10ms/step - loss: 0.7966 - accuracy: 0.7284\n",
            "Epoch 140/200\n",
            "177/177 [==============================] - 2s 10ms/step - loss: 0.7867 - accuracy: 0.7311\n",
            "Epoch 141/200\n",
            "177/177 [==============================] - 2s 10ms/step - loss: 0.8024 - accuracy: 0.7249\n",
            "Epoch 142/200\n",
            "177/177 [==============================] - 2s 11ms/step - loss: 0.7867 - accuracy: 0.7358\n",
            "Epoch 143/200\n",
            "177/177 [==============================] - 2s 11ms/step - loss: 0.7696 - accuracy: 0.7353\n",
            "Epoch 144/200\n",
            "177/177 [==============================] - 2s 10ms/step - loss: 0.7708 - accuracy: 0.7311\n",
            "Epoch 145/200\n",
            "177/177 [==============================] - 2s 10ms/step - loss: 0.7687 - accuracy: 0.7314\n",
            "Epoch 146/200\n",
            "177/177 [==============================] - 2s 10ms/step - loss: 0.7653 - accuracy: 0.7349\n",
            "Epoch 147/200\n",
            "177/177 [==============================] - 2s 10ms/step - loss: 0.7691 - accuracy: 0.7281\n",
            "Epoch 148/200\n",
            "177/177 [==============================] - 2s 10ms/step - loss: 0.7701 - accuracy: 0.7364\n",
            "Epoch 149/200\n",
            "177/177 [==============================] - 2s 10ms/step - loss: 0.7663 - accuracy: 0.7371\n",
            "Epoch 150/200\n",
            "177/177 [==============================] - 2s 10ms/step - loss: 0.7634 - accuracy: 0.7325\n",
            "Epoch 151/200\n",
            "177/177 [==============================] - 2s 11ms/step - loss: 0.7668 - accuracy: 0.7328\n",
            "Epoch 152/200\n",
            "177/177 [==============================] - 2s 10ms/step - loss: 0.7757 - accuracy: 0.7357\n",
            "Epoch 153/200\n",
            "177/177 [==============================] - 2s 11ms/step - loss: 0.8112 - accuracy: 0.7203\n",
            "Epoch 154/200\n",
            "177/177 [==============================] - 2s 11ms/step - loss: 0.8395 - accuracy: 0.7185\n",
            "Epoch 155/200\n",
            "177/177 [==============================] - 2s 10ms/step - loss: 0.7913 - accuracy: 0.7316\n",
            "Epoch 156/200\n",
            "177/177 [==============================] - 2s 10ms/step - loss: 0.7678 - accuracy: 0.7337\n",
            "Epoch 157/200\n",
            "177/177 [==============================] - 2s 10ms/step - loss: 0.7527 - accuracy: 0.7353\n",
            "Epoch 158/200\n",
            "177/177 [==============================] - 2s 10ms/step - loss: 0.7520 - accuracy: 0.7335\n",
            "Epoch 159/200\n",
            "177/177 [==============================] - 2s 10ms/step - loss: 0.7477 - accuracy: 0.7394\n",
            "Epoch 160/200\n",
            "177/177 [==============================] - 2s 10ms/step - loss: 0.7468 - accuracy: 0.7360\n",
            "Epoch 161/200\n",
            "177/177 [==============================] - 2s 10ms/step - loss: 0.7465 - accuracy: 0.7418\n",
            "Epoch 162/200\n",
            "177/177 [==============================] - 2s 10ms/step - loss: 0.7507 - accuracy: 0.7357\n",
            "Epoch 163/200\n",
            "177/177 [==============================] - 2s 11ms/step - loss: 0.7511 - accuracy: 0.7369\n",
            "Epoch 164/200\n",
            "177/177 [==============================] - 2s 11ms/step - loss: 0.7560 - accuracy: 0.7323\n",
            "Epoch 165/200\n",
            "177/177 [==============================] - 2s 10ms/step - loss: 0.7541 - accuracy: 0.7335\n",
            "Epoch 166/200\n",
            "177/177 [==============================] - 2s 10ms/step - loss: 0.7568 - accuracy: 0.7341\n",
            "Epoch 167/200\n",
            "177/177 [==============================] - 2s 10ms/step - loss: 0.7582 - accuracy: 0.7323\n",
            "Epoch 168/200\n",
            "177/177 [==============================] - 2s 10ms/step - loss: 0.7922 - accuracy: 0.7288\n",
            "Epoch 169/200\n",
            "177/177 [==============================] - 2s 10ms/step - loss: 0.8323 - accuracy: 0.7169\n",
            "Epoch 170/200\n",
            "177/177 [==============================] - 2s 10ms/step - loss: 0.7664 - accuracy: 0.7314\n",
            "Epoch 171/200\n",
            "177/177 [==============================] - 2s 10ms/step - loss: 0.7474 - accuracy: 0.7344\n",
            "Epoch 172/200\n",
            "177/177 [==============================] - 2s 10ms/step - loss: 0.7426 - accuracy: 0.7357\n",
            "Epoch 173/200\n",
            "177/177 [==============================] - 2s 10ms/step - loss: 0.7395 - accuracy: 0.7339\n",
            "Epoch 174/200\n",
            "177/177 [==============================] - 2s 10ms/step - loss: 0.7377 - accuracy: 0.7344\n",
            "Epoch 175/200\n",
            "177/177 [==============================] - 2s 11ms/step - loss: 0.7343 - accuracy: 0.7371\n",
            "Epoch 176/200\n",
            "177/177 [==============================] - 2s 10ms/step - loss: 0.7419 - accuracy: 0.7360\n",
            "Epoch 177/200\n",
            "177/177 [==============================] - 2s 11ms/step - loss: 0.7416 - accuracy: 0.7379\n",
            "Epoch 178/200\n",
            "177/177 [==============================] - 2s 10ms/step - loss: 0.7489 - accuracy: 0.7327\n",
            "Epoch 179/200\n",
            "177/177 [==============================] - 2s 10ms/step - loss: 0.7710 - accuracy: 0.7307\n",
            "Epoch 180/200\n",
            "177/177 [==============================] - 2s 10ms/step - loss: 0.7717 - accuracy: 0.7300\n",
            "Epoch 181/200\n",
            "177/177 [==============================] - 2s 10ms/step - loss: 0.7613 - accuracy: 0.7298\n",
            "Epoch 182/200\n",
            "177/177 [==============================] - 2s 10ms/step - loss: 0.7854 - accuracy: 0.7226\n",
            "Epoch 183/200\n",
            "177/177 [==============================] - 2s 11ms/step - loss: 0.7434 - accuracy: 0.7323\n",
            "Epoch 184/200\n",
            "177/177 [==============================] - 2s 11ms/step - loss: 0.7341 - accuracy: 0.7388\n",
            "Epoch 185/200\n",
            "177/177 [==============================] - 2s 10ms/step - loss: 0.7331 - accuracy: 0.7404\n",
            "Epoch 186/200\n",
            "177/177 [==============================] - 2s 10ms/step - loss: 0.7339 - accuracy: 0.7349\n",
            "Epoch 187/200\n",
            "177/177 [==============================] - 2s 11ms/step - loss: 0.7340 - accuracy: 0.7327\n",
            "Epoch 188/200\n",
            "177/177 [==============================] - 2s 10ms/step - loss: 0.7328 - accuracy: 0.7344\n",
            "Epoch 189/200\n",
            "177/177 [==============================] - 2s 11ms/step - loss: 0.7376 - accuracy: 0.7344\n",
            "Epoch 190/200\n",
            "177/177 [==============================] - 2s 10ms/step - loss: 0.7486 - accuracy: 0.7344\n",
            "Epoch 191/200\n",
            "177/177 [==============================] - 2s 10ms/step - loss: 0.7510 - accuracy: 0.7316\n",
            "Epoch 192/200\n",
            "177/177 [==============================] - 2s 10ms/step - loss: 0.7895 - accuracy: 0.7265\n",
            "Epoch 193/200\n",
            "177/177 [==============================] - 2s 11ms/step - loss: 0.7940 - accuracy: 0.7208\n",
            "Epoch 194/200\n",
            "177/177 [==============================] - 2s 12ms/step - loss: 0.7606 - accuracy: 0.7296\n",
            "Epoch 195/200\n",
            "177/177 [==============================] - 2s 11ms/step - loss: 0.7443 - accuracy: 0.7323\n",
            "Epoch 196/200\n",
            "177/177 [==============================] - 2s 12ms/step - loss: 0.7266 - accuracy: 0.7323\n",
            "Epoch 197/200\n",
            "177/177 [==============================] - 2s 11ms/step - loss: 0.7275 - accuracy: 0.7351\n",
            "Epoch 198/200\n",
            "177/177 [==============================] - 2s 11ms/step - loss: 0.7257 - accuracy: 0.7367\n",
            "Epoch 199/200\n",
            "177/177 [==============================] - 2s 11ms/step - loss: 0.7278 - accuracy: 0.7332\n",
            "Epoch 200/200\n",
            "177/177 [==============================] - 2s 10ms/step - loss: 0.7234 - accuracy: 0.7381\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d2NAc-iLWlv4",
        "outputId": "bcbf3f8d-9436-4b53-858a-907ff47bae4a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_graph(model_train,string):\n",
        "  plt.plot(model_train.history[string])\n",
        "  plt.xlabel('Epochs')\n",
        "  plt.ylabel(string)\n",
        "  plt.show()\n",
        "\n",
        "plot_graph(model_train,'accuracy')"
      ],
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eBanDEXXbE6x"
      },
      "source": [
        "We can see that the accuracy is constant after 100 epochs hence we can train the network between 100 and 120 epochs and get the same accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zVfrIz8kZ7MT"
      },
      "source": [
        "### Predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zTU7i9BAaINj",
        "outputId": "c45a5c37-02e5-4390-8dba-10456fc698ff",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "text=['are you','can you','do you need','are you free']\n",
        "next_words=5\n",
        "\n",
        "for words in text:\n",
        "  for _ in range(next_words):\n",
        "    token_list=tokenizer.texts_to_sequences([words])[0]\n",
        "    token_list=pad_sequences([token_list],maxlen=max_sequence_len-1,padding='pre')\n",
        "    predicted=np.argmax(model.predict(token_list),axis=1)\n",
        "    output_word=''\n",
        "    for word,index in tokenizer.word_index.items():\n",
        "      if index==predicted:\n",
        "        output_word=word\n",
        "        break\n",
        "    words+=' ,'+output_word\n",
        "  print(words)"
      ],
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "are you ,going ,or ,not ,the ,way\n",
            "can you ,say ,that ,s ,life ,in\n",
            "do you need ,think ,it ,has ,nt ,be\n",
            "are you free ,going ,or ,not ,the ,way\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NX-Em0vodvRq"
      },
      "source": [
        ""
      ],
      "execution_count": 131,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qTwblYDWaL-l"
      },
      "source": [
        ""
      ],
      "execution_count": 131,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8vbTema0bVQI"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}